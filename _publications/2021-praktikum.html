---
layout: publication
authors:
  - Moritz Sch√ºler
  - Amine Bentellis
  - Arpit Karwasara
highlight: true
pdf: link_to_arxiv.pdf
arxiv: "arxiv_number"
tags:
  - Explainable AI
  - NLP
title: Global Explainability for understanding opinions on social media
description: We provide a script to train a BERT model on social media data and afterwards analyze the prediction.
link: https://github.com/MoritzSchueler96/TUM_Praktikum_NLP_Explainability
type:
  - Journal
year: 2021
---

In this age of social media we have a immense
amount of data that these platforms can provide. It becomes extremely hard to find new
and innovative ways to extract value from that
data. In this paper we work on analyzing the
impact, ideology and stance of several social
media channels to enhance the understanding
of opinions on social media. For this we collected our own dataset in the form of Facebook
posts from CrowdTangle and also used the SemEval Stance dataset consisting of tweets with
annotated sentiment and stance. Additionally
we provide more insights into the model output by using several global eXplainable Artificial Intelligence (XAI)
techniques. Specifically, we leverage SAGE and Neuron Attribution for global explainability.
